{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP preprocessing\n",
    "- 토큰화(tokenization)\n",
    "- PoS Parts-of-Speech 태깅\n",
    "- 불용어(stop word) 제거\n",
    "- 텍스트 정규화(text normalization)\n",
    "  - 철자 수정(spelling correction)\n",
    "  - 어간 추출(stemming)(형태소 분석)\n",
    "  - 표제어 추출(lemmatization)\n",
    "- 개체명 인식(Named Entity Recognition)(NER)\n",
    "- 단어 중의성 해결(word sense disambiguation)\n",
    "- 문장 경계 인식(sentence boundary detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/shane/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'reading', 'NLP', 'Fundamentals']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "words = word_tokenize('I am reading NLP Fundamentals')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/shane/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('reading', 'VBG'),\n",
       " ('NLP', 'NNP'),\n",
       " ('Fundamentals', 'NNS')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PoS(Parts of Speech) tagging\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "\n",
    "pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we']...179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/shane/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# removing stop words\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "en_stopwords = stopwords.words('english')\n",
    "print(f'{stop_words[:5]}...{len(en_stopwords)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------original-----------\n",
      "Python was created in the early 1990s by Guido van Rossum at Stichting Mathematisch Centrum (CWI, see https://www.cwi.nl/) in the Netherlands as a successor of a language called ABC. Guido remains Python’s principal author, although it includes many contributions from others.\n",
      "----------stopwords-----------\n",
      "Python created early 1990s Guido van Rossum Stichting Mathematisch Centrum ( CWI , see https : //www.cwi.nl/ ) Netherlands successor language called ABC . Guido remains Python ’ principal author , although includes many contributions others .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/shane/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/shane/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "sentence = 'Python was created in the early 1990s by Guido van Rossum at Stichting Mathematisch Centrum (CWI, see https://www.cwi.nl/) in the Netherlands as a successor of a language called ABC. Guido remains Python’s principal author, although it includes many contributions from others.'\n",
    "print(f'{\"original\":-^30}')\n",
    "print(sentence)\n",
    "\n",
    "words = word_tokenize(sentence)\n",
    "en_stopwords = stopwords.words('english')\n",
    "print(f'{\"stopwords\":-^30}')\n",
    "print(' '.join([word for word in words if word not in en_stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural Language Processing deals with the art of extracting insights from Natural Language'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize -> autocorrect -> PoS\n",
    "# stemming -> autocorrect\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from autocorrect import Speller\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "sentence = 'Natureal Languaage Proccessing deals with the art of extractiing insights from Natyral Langualge'\n",
    "spell = Speller(lang='en')\n",
    "' '.join(map(spell, word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'water'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming\n",
    "\n",
    "import nltk\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "stemmer.stem('waterings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/shane/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('watering', 'water')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize('waterings'), lemmatizer.lemmatize('waterings', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/shane/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/shane/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('quick', 'JJ'),\n",
       " ('brown', 'NN'),\n",
       " ('fox', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('showed', 'VBD'),\n",
       " ('up', 'IN'),\n",
       " ('last', 'JJ'),\n",
       " ('dark', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('stormy', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('jumps', 'NNS'),\n",
       " ('over', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('lazy', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named Entity Recognition (NER)\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "sentence = 'The quick brown fox that showed up last dark and stormy night jumps over the lazy dog.'\n",
    "i = nltk.ne_chunk(nltk.pos_tag(word_tokenize(sentence)), binary=True)\n",
    "list(i)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58907fe78f63c93a3114ab5e0fdb36e51d265a83145a0a6852cc052e563a673e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
